# Training

defaults:
  - config

hydra:
  run:
    dir: ${train.train_dir}

dataset:
  type: 'single' # 'single' or 'multi'
  images: True
  in_shape: [320, 160, 6]
  cache: True # load episodes to memory instead of reading from disk
  augment:
    theta_sigma: 60 # rotation sigma in degrees; N(mu = 0, sigma = theta_sigma).
  
conceptfusion:
  model_type: vit_h
  checkpoint_path: /home/a/acw799/concept-fusion/code/gradslam-foundation/examples/checkpoints/sam_vit_h_4b8939.pth
  save_dir: saved-feat
  desired_height: 160
  desired_width: 320

train:
  # folders
  exp_folder: exps
  train_dir: ${root_dir}/${train.exp_folder}/${train.task}-${train.agent}-n${train.n_demos}-train
  data_dir: /home/a/acw799/data

  # task configs
  task: packing-boxes-pairs-seen-colors
  agent: two_stream_full_clip_lingunet_lat_transporter
  n_demos: 1000
  n_steps: 201000 # use 601000 for multi-task models

  # hyper params
  n_rotations: 36
  batchnorm: False # important: False because batch_size=1
  lr: 1e-4
  eps: 1e-8

  attn_stream_fusion_type: 'add'
  trans_stream_fusion_type: 'conv'
  lang_fusion_type: 'mult'

  # script configs
  gpu: [0] # -1 for all
  log: False # log metrics and stats to wandb
  n_val: 100
  val_repeats: 1
  save_steps: [1, 1000, 2000, 3000, 4000, 5000, 7000, 10000, 20000, 40000, 80000, 120000, 160000, 200000, 220000, 240000, 260000, 280000, 300000, 400000, 500000, 600000, 800000, 1000000, 1200000]
  load_from_last_ckpt: True

  # prompt learning
  cocoop:
    n_ctx: 4
    # ctx_init: None  
    ctx_init: "a photo of that"
    prec: "fp16"
  coop:
    n_ctx: 4
    ctx_init: None
    prec: "fp16"

wandb:
  run_name: 'cliport0'
  logger:
    entity: cliport
    project: cliport
    tags: []
    group: train
    offline: False
  saver:
    upload: False
    monitor: 'val_loss'