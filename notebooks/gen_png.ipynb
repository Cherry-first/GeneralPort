{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:45:17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cliport.utils import utils\n",
    "from cliport import tasks\n",
    "from cliport.dataset import RavensDataset\n",
    "from cliport.environments.environment import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export PATH=/path/to/specific/jupyter/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_demos = 4\n",
    "mode = \"val\"\n",
    "task = 'put-block-in-bowl-seen-colors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 'dataset.in_shape' not found, using default value.\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/a/acw799/cliport'\n",
    "data_dir = '/home/a/acw799'\n",
    "assets_root = os.path.join(root_dir, 'cliport/environments/assets/')\n",
    "config_file = 'eval.yaml' \n",
    "vcfg = utils.load_hydra_config(os.path.join(root_dir, f'cliport/cfg/{config_file}'))\n",
    "vcfg['data_dir'] = os.path.join(data_dir, 'data')\n",
    "vcfg['mode'] = mode\n",
    "vcfg['task'] = task\n",
    "vcfg['train_config'] = \"cliport/cfg/inference.yaml\"\n",
    "tcfg = utils.load_hydra_config(vcfg['train_config'])\n",
    "\n",
    "# Load dataset\n",
    "ds = RavensDataset(os.path.join(vcfg['data_dir'], f'{vcfg[\"task\"]}-{vcfg[\"mode\"]}'), \n",
    "                   tcfg, \n",
    "                   n_demos=n_demos,\n",
    "                   augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/a/acw799/data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcfg['data_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment and task.\n",
    "env = Environment(\n",
    "    assets_root,\n",
    "    disp=False,\n",
    "    shared_memory=False,\n",
    "    hz=480,\n",
    "    record_cfg=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建文件夹路径\n",
    "color_dir = \"/home/a/acw799/cliport/data/unseen/color\"\n",
    "depth_dir = \"/home/a/acw799/cliport/data/unseen/depth\"\n",
    "\n",
    "# 确保文件夹存在\n",
    "os.makedirs(color_dir, exist_ok=True)\n",
    "os.makedirs(depth_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving color and depth:: 100%|██████████| 4/4 [00:24<00:00,  6.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(n_demos), desc=\"saving color and depth:\", total=n_demos):\n",
    "    episode, seed = ds.load(i)\n",
    "\n",
    "     # Set task\n",
    "    task_name = vcfg['task']\n",
    "    task = tasks.names[task_name]()\n",
    "    task.mode = mode\n",
    "\n",
    "    # Set environment\n",
    "    env.seed(seed)\n",
    "    env.set_task(task)\n",
    "    obs = env.reset()\n",
    "    info = env.info\n",
    "    reward = 0\n",
    "         \n",
    "    # Get batch\n",
    "    batch = ds.process_goal((obs, None, reward, info), perturb_params=None)\n",
    "    \n",
    "    # Get color and depth inputs\n",
    "    img = batch['img']\n",
    "    img = torch.from_numpy(img)\n",
    "    color = np.uint8(img.detach().cpu().numpy())[:,:,:3]\n",
    "    color = color.transpose(1,0,2)\n",
    "\n",
    "    depth = np.array(img.detach().cpu().numpy())[:,:,3]\n",
    "    depth = depth.transpose(1,0)\n",
    "\n",
    "    # save .png files\n",
    "    color_filename = os.path.join(color_dir, f\"{i:05}.png\")\n",
    "    depth_filename = os.path.join(depth_dir, f\"{i:05}.png\")\n",
    "    # 保存彩色图像\n",
    "    imageio.imwrite(color_filename, color)  # color(H, W, 3)\n",
    "    \n",
    "    # 保存深度图像（以灰度图保存）\n",
    "    normalized_depth = (255 * (depth / depth.max())).astype(np.uint8)  # 归一化到 [0, 255]\n",
    "    imageio.imwrite(depth_filename, normalized_depth)\n",
    "\n",
    "    # fig, axs = plt.subplots(1, 2, figsize=(13, 7))\n",
    "    # # Display input color\n",
    "    # axs[0].imshow(color)\n",
    "    # axs[0].axes.xaxis.set_visible(False)\n",
    "    # axs[0].axes.yaxis.set_visible(False)\n",
    "    # axs[0].set_title('Input RGB sample')\n",
    "    \n",
    "    # # Display input depth\n",
    "    # axs[1].imshow(normalized_depth)\n",
    "    # axs[1].axes.xaxis.set_visible(False)\n",
    "    # axs[1].axes.yaxis.set_visible(False)        \n",
    "    # axs[1].set_title('Input Depth sample')\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch24_env)",
   "language": "python",
   "name": "torch24_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
